diff -urN linux-4.4.1-origin/drivers/vhost/net.c linux-4.4.1/drivers/vhost/net.c
--- linux-4.4.1-origin/drivers/vhost/net.c	2016-02-01 04:29:37.000000000 +0900
+++ linux-4.4.1/drivers/vhost/net.c	2018-07-05 14:53:37.293797989 +0900
@@ -30,6 +30,11 @@
 
 #include "vhost.h"
 
+#ifdef ANCS
+LIST_HEAD(ancs_proc_list);
+EXPORT_SYMBOL(ancs_proc_list);
+int count = 1;
+#endif
 static int experimental_zcopytx = 1;
 module_param(experimental_zcopytx, int, 0444);
 MODULE_PARM_DESC(experimental_zcopytx, "Enable Zero Copy TX;"
@@ -109,6 +114,9 @@
 	unsigned tx_zcopy_err;
 	/* Flush in progress. Protected by tx vq lock. */
 	bool tx_flush;
+#ifdef ANCS
+	struct ancs_vm *vnet;
+#endif
 };
 
 static unsigned vhost_net_zcopy_mask __read_mostly;
@@ -295,6 +303,10 @@
 	struct vhost_virtqueue *vq = &nvq->vq;
 	unsigned out, in;
 	int head;
+#ifdef ANCS
+	struct ancs_vm *vnet = net->vnet;
+	struct list_head *ancs_head;
+#endif	
 	struct msghdr msg = {
 		.msg_name = NULL,
 		.msg_namelen = 0,
@@ -353,6 +365,22 @@
 		}
 		/* Skip header. TODO: support TSO. */
 		len = iov_length(vq->iov, out);
+#ifdef ANCS
+		ancs_head=&vnet->active_list;
+		if (ancs_head! = ancs_head->prev) { 
+			if(len > vnet->remaining_credit) {
+				vnet->need_reschedule = true;
+				vhost_discard_vq_desc(vq, 1);
+				if (unlikely(vhost_enable_notify(&net->dev, vq))) { 
+					vhost_disable_notify(&net->dev, vq);
+					continue;
+				}
+				break;
+			}
+			vnet->remaining_credit -= len;
+			vnet->used_credit += len;
+		}
+#endif
 		iov_iter_init(&msg.msg_iter, WRITE, vq->iov, out, len);
 		iov_iter_advance(&msg.msg_iter, hdr_size);
 		/* Sanity check */
@@ -678,7 +706,9 @@
 	struct vhost_dev *dev;
 	struct vhost_virtqueue **vqs;
 	int i;
-
+#ifdef ANCS
+	struct ancs_vm *vnet;
+#endif
 	n = kmalloc(sizeof *n, GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);
 	if (!n) {
 		n = vmalloc(sizeof *n);
@@ -711,6 +741,33 @@
 
 	f->private_data = n;
 
+#ifdef ANCS
+	vnet = kmalloc(sizeof(struct ancs_vm), GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);
+	if(!vnet) {
+		kvfree(n);
+		kfree(vqs);
+		return -ENOMEM;
+	}
+	
+	INIT_LIST_HEAD(&vnet->proc_list);
+	list_add(&vnet->proc_list, &ancs_proc_list);
+	n->vnet = vnet;
+	INIT_LIST_HEAD(&vnet->active_list);
+	vnet->id = count++;
+	vnet->remaining_credit = 0;
+	vnet->weight = vnet->id;
+	vnet->max_credit = 0;
+	vnet->min_credit = 0;
+	vnet->used_credit = 0;
+	vnet->need_reschedule = false;
+	vnet->poll = n->poll;
+#ifdef CPU_CONTROL
+	vnet->stat.cpu_usage = 0;
+	vnet->stat.nw_usage = 0;
+	vnet->stat.virq = 0;
+	vnet->stat.flag = 3;
+#endif	
+#endif
 	return 0;
 }
 
@@ -803,6 +860,9 @@
 	/* We do an extra flush before freeing memory,
 	 * since jobs can re-queue themselves. */
 	vhost_net_flush(n);
+#ifdef ANCS
+	kfree(n->vnet);
+#endif
 	kfree(n->dev.vqs);
 	kvfree(n);
 	return 0;
@@ -1043,6 +1103,9 @@
 	if (r)
 		vhost_net_clear_ubuf_info(n);
 	vhost_net_flush(n);
+#ifdef ANCS
+	n->vnet->vhost = current;
+#endif
 out:
 	mutex_unlock(&n->dev.mutex);
 	return r;
diff -urN linux-4.4.1-origin/drivers/vhost/vhost.h linux-4.4.1/drivers/vhost/vhost.h
--- linux-4.4.1-origin/drivers/vhost/vhost.h	2016-02-01 04:29:37.000000000 +0900
+++ linux-4.4.1/drivers/vhost/vhost.h	2018-07-05 14:53:32.025885471 +0900
@@ -1,6 +1,7 @@
 #ifndef _VHOST_H
 #define _VHOST_H
 
+#define ANCS
 #include <linux/eventfd.h>
 #include <linux/vhost.h>
 #include <linux/mm.h>
@@ -35,6 +36,33 @@
 	struct vhost_dev	 *dev;
 };
 
+#ifdef ANCS
+#define MAX_NUMBER_VCPU	4
+struct ancs_stat {
+	unsigned int cpu_usage;
+	unsigned int nw_usage;
+	unsigned int virq;
+	int flag;
+};
+struct ancs_vm {
+	struct list_head active_list;
+	unsigned int weight;
+	bool need_reschedule;
+	unsigned int remaining_credit;
+	unsigned int min_credit;
+	unsigned int max_credit;
+	unsigned int used_credit;
+	int id;
+	struct list_head proc_list
+	struct vhost_poll *poll;
+	struct task_struct *vhost;
+
+#ifdef CPU_CONTROL	
+	struct task_struct *vcpu[MAX_NUMBER_VCPU];
+	struct ancs_stat stat;
+#endif
+};
+#endif
 void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn);
 void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work);
 
diff -urN linux-4.4.1-origin/kernel/sched/core.c linux-4.4.1/kernel/sched/core.c
--- linux-4.4.1-origin/kernel/sched/core.c	2016-02-01 04:29:37.000000000 +0900
+++ linux-4.4.1/kernel/sched/core.c	2018-07-05 14:53:58.297449206 +0900
@@ -8376,6 +8376,7 @@
 
 	return tg_set_cfs_bandwidth(tg, period, quota);
 }
+EXPORT_SYMBOL(tg_set_cfs_quota);
 
 long tg_get_cfs_quota(struct task_group *tg)
 {
@@ -8389,6 +8390,7 @@
 
 	return quota_us;
 }
+EXPORT_SYMBOL(tg_get_cfs_quota);
 
 int tg_set_cfs_period(struct task_group *tg, long cfs_period_us)
 {
@@ -8399,6 +8401,7 @@
 
 	return tg_set_cfs_bandwidth(tg, period, quota);
 }
+EXPORT_SYMBOL(tg_set_cfs_period);
 
 long tg_get_cfs_period(struct task_group *tg)
 {
@@ -8409,6 +8412,7 @@
 
 	return cfs_period_us;
 }
+EXPORT_SYMBOL(tg_get_cfs_period);
 
 static s64 cpu_cfs_quota_read_s64(struct cgroup_subsys_state *css,
 				  struct cftype *cft)
